{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing the relevant packages and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/susmeet/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(X):\n",
    "    \n",
    "    # remove the colum that has ~20% null values, also ranks low on feature importance\n",
    "    X.drop(['ndvi_ne'], axis=1, inplace=True)\n",
    "    \n",
    "    # Filling the rest using linear interpolation\n",
    "    X.interpolate(inplace=True)\n",
    "\n",
    "def remove_outliers(df):\n",
    "    return df[(np.abs(stats.zscore(df)) < 5).all(axis=1)]\n",
    "\n",
    "def mape(Y_test, Y_pred, epsilon = 1):\n",
    "    return np.mean(np.abs((Y_test - Y_pred + epsilon) / (Y_test + epsilon))) * 100\n",
    "\n",
    "def extract_month(s):\n",
    "    return int(s[5:7])\n",
    "\n",
    "def city_indices(X):\n",
    "    # city boolean encoding\n",
    "    return X.city == 'sj'\n",
    "\n",
    "def pre_process(X, y, trees = False):\n",
    "    \"\"\"\n",
    "    Extracts the month out of date and converts it to a one hot\n",
    "    Standardizes the numerical features\n",
    "    \"\"\"\n",
    "    \n",
    "    #Extracting month from the date\n",
    "    months = X.week_start_date.apply(extract_month)\n",
    "    \n",
    "    #Response coding\n",
    "#     month = X.week_start_date.apply(extract_month)\n",
    "#     temp = pd.DataFrame(y.total_cases)\n",
    "#     temp['month'] = month\n",
    "#     for name,group in temp.groupby(month):\n",
    "#         month[group.index] = np.median(group.total_cases)\n",
    "        \n",
    "    # Removing the columns not required for classification\n",
    "    X.drop(['city', 'year', 'weekofyear', 'week_start_date'], axis=1, inplace=True)\n",
    "\n",
    "    # Standardizing the data\n",
    "    if not trees:\n",
    "        scaler = StandardScaler()\n",
    "        X[X.columns] = scaler.fit_transform(X)\n",
    "\n",
    "    # Month one hot features\n",
    "    month_features = pd.get_dummies(months, prefix='m_')\n",
    "    X = X.join(month_features)\n",
    "\n",
    "    #Alternatively use response coding \n",
    "#     X = X.join(month)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def seperate_cities_data(X, is_sj):\n",
    "\n",
    "    # Seperating the cities data\n",
    "    X_sj = X.loc[is_sj]\n",
    "    X_iq = X.loc[~is_sj]\n",
    "    \n",
    "    return X_sj, X_iq\n",
    "\n",
    "def get_y_labels(X_sj, X_iq, y):    \n",
    "    \n",
    "    y = y.total_cases    \n",
    "    y_sj = y.loc[X_sj.index]\n",
    "    y_iq = y.loc[X_iq.index]\n",
    "    \n",
    "    return y_sj, y_iq\n",
    "\n",
    "def split(X_sj, X_iq, y_sj, y_iq):\n",
    "\n",
    "    # train and test split\n",
    "    sj_split_data = train_test_split(X_sj, y_sj, shuffle = False)\n",
    "    iq_split_data = train_test_split(X_iq, y_iq, shuffle = False)\n",
    "\n",
    "    return sj_split_data, iq_split_data\n",
    "\n",
    "def process(X, y = pd.Series(), train = True, trees = False, feature_selection = 0, time_shift = 0):\n",
    "    \n",
    "    is_sj = city_indices(X)\n",
    "    if not trees:\n",
    "        impute(X)\n",
    "    X = pre_process(X, y, trees)\n",
    "    \n",
    "    if feature_selection:\n",
    "        selector = SelectKBest(f_regression, k=feature_selection).fit(X,y.total_cases)\n",
    "        X = X.loc[:,selector.get_support()]\n",
    "\n",
    "    #X = remove_outliers(X)\n",
    "    X_sj, X_iq = seperate_cities_data(X, is_sj)\n",
    "    if y.empty:\n",
    "        return X_sj, X_iq\n",
    "    \n",
    "    y_sj, y_iq = get_y_labels(X_sj, X_iq, y)\n",
    "    if time_shift:\n",
    "        y_sj = y_sj.shift(time_shift).dropna()\n",
    "        y_iq = y_iq.shift(time_shift).dropna()\n",
    "        X_sj = X_sj[:-time_shift]\n",
    "        X_iq = X_iq[:-time_shift]\n",
    "        \n",
    "    if not train:\n",
    "        return X_sj, X_iq, y_sj, y_iq\n",
    "    \n",
    "    return split(X_sj, X_iq, y_sj, y_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"dengue_features_train.csv\")\n",
    "y = pd.read_csv(\"dengue_labels_train.csv\")\n",
    "test = pd.read_csv(\"dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process(X,y)\n",
    "\n",
    "(X_sj_train, X_sj_test, Y_sj_train, Y_sj_test), (X_iq_train, X_iq_test, Y_iq_train, Y_iq_test) = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702          NaN\n",
       "703          NaN\n",
       "704          NaN\n",
       "705          NaN\n",
       "706          NaN\n",
       "707          NaN\n",
       "708          NaN\n",
       "709          NaN\n",
       "710          NaN\n",
       "711          NaN\n",
       "712          NaN\n",
       "713    26.666667\n",
       "714    24.250000\n",
       "715    22.750000\n",
       "716    21.083333\n",
       "717    19.750000\n",
       "718    17.416667\n",
       "719    15.916667\n",
       "720    14.166667\n",
       "721    13.416667\n",
       "722    12.166667\n",
       "723    11.833333\n",
       "724    10.500000\n",
       "725     9.583333\n",
       "726     8.916667\n",
       "727     7.666667\n",
       "728     7.333333\n",
       "729     6.750000\n",
       "730     6.416667\n",
       "731     5.750000\n",
       "         ...    \n",
       "906    82.750000\n",
       "907    90.666667\n",
       "908    96.000000\n",
       "909    98.666667\n",
       "910    96.666667\n",
       "911    94.416667\n",
       "912    90.250000\n",
       "913    85.333333\n",
       "914    81.833333\n",
       "915    73.916667\n",
       "916    66.083333\n",
       "917    58.750000\n",
       "918    46.000000\n",
       "919    36.000000\n",
       "920    28.333333\n",
       "921    23.916667\n",
       "922    20.750000\n",
       "923    17.500000\n",
       "924    15.500000\n",
       "925    13.250000\n",
       "926    11.500000\n",
       "927    10.500000\n",
       "928     9.583333\n",
       "929     8.666667\n",
       "930     7.500000\n",
       "931     6.583333\n",
       "932     5.666667\n",
       "933     4.500000\n",
       "934     3.916667\n",
       "935     3.583333\n",
       "Name: total_cases, Length: 234, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.rolling_mean(Y_sj_test, window = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = ' + '.join([str(i) for i in list(X_sj_train.columns)])\n",
    "formula = 'y ~ ' + formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv error: 22.602564102564102\n",
      "train error: 25.478632478632477\n"
     ]
    }
   ],
   "source": [
    "train_sj = X_sj_train.copy()\n",
    "train_sj['y'] = Y_sj_train\n",
    "test_sj = X_sj_test.copy()\n",
    "\n",
    "model = smf.glm(formula=formula,\n",
    "                data=train_sj,\n",
    "                family=sm.families.NegativeBinomial())\n",
    "model = model.fit()\n",
    "\n",
    "predictions_sj = model.predict(test_sj).astype(int)\n",
    "print (\"cv error:\", mean_absolute_error(predictions_sj, Y_sj_test))\n",
    "\n",
    "pred_train_sj = model.predict(train_sj).astype(int)\n",
    "print (\"train error:\", mean_absolute_error(pred_train_sj, Y_sj_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv error: 8.069230769230769\n",
      "train error: 5.441025641025641\n"
     ]
    }
   ],
   "source": [
    "train_iq = X_iq_train.copy()\n",
    "train_iq['y'] = Y_iq_train\n",
    "test_iq = X_iq_test.copy()\n",
    "\n",
    "model = smf.glm(formula=formula,\n",
    "                data=train_iq,\n",
    "                family=sm.families.NegativeBinomial())\n",
    "results = model.fit()\n",
    "\n",
    "predictions_iq = results.predict(test_iq).astype(int)\n",
    "print (\"cv error:\", mean_absolute_error(predictions_iq, Y_iq_test))\n",
    "\n",
    "pred_train_iq = results.predict(train_iq).astype(int)\n",
    "print (\"train error:\", mean_absolute_error(pred_train_iq, Y_iq_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv error: 17.412087912087912\n",
      "train error: 18.32234432234432\n"
     ]
    }
   ],
   "source": [
    "pred = predictions_iq.append(predictions_sj)\n",
    "true = Y_iq_test.append(Y_sj_test)\n",
    "print (\"cv error:\", mean_absolute_error(pred, true))\n",
    "\n",
    "train_pred = pred_train_iq.append(pred_train_sj)\n",
    "train_true = Y_iq_train.append(Y_sj_train)\n",
    "print (\"train error:\", mean_absolute_error(train_pred, train_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = []\n",
    "train_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(2,32):\n",
    "    \n",
    "    X = pd.read_csv(\"dengue_features_train.csv\")\n",
    "    y = pd.read_csv(\"dengue_labels_train.csv\")\n",
    "    test = pd.read_csv(\"dengue_features_test.csv\")\n",
    "\n",
    "    data = process(X,y,feature_selection=k)\n",
    "\n",
    "    (X_sj_train, X_sj_test, Y_sj_train, Y_sj_test), (X_iq_train, X_iq_test, Y_iq_train, Y_iq_test) = data\n",
    "\n",
    "    formula = ' + '.join([str(i) for i in list(X_sj_train.columns)])\n",
    "    formula = 'y ~ ' + formula\n",
    "    # sj\n",
    "    train_sj = X_sj_train.copy()\n",
    "    train_sj['y'] = Y_sj_train\n",
    "    test_sj = X_sj_test.copy()\n",
    "\n",
    "    model = smf.glm(formula=formula,\n",
    "                    data=train_sj,\n",
    "                    family=sm.families.NegativeBinomial())\n",
    "    model = model.fit()\n",
    "    predictions_sj = model.predict(test_sj).astype(int)\n",
    "    pred_train_sj = model.predict(train_sj).astype(int)\n",
    "    \n",
    "    # iq\n",
    "    train_iq = X_iq_train.copy()\n",
    "    train_iq['y'] = Y_iq_train\n",
    "    test_iq = X_iq_test.copy()\n",
    "\n",
    "    model = smf.glm(formula=formula,\n",
    "                    data=train_iq,\n",
    "                    family=sm.families.NegativeBinomial())\n",
    "    results = model.fit()\n",
    "\n",
    "    predictions_iq = results.predict(test_iq).astype(int)\n",
    "    pred_train_iq = results.predict(train_iq).astype(int)\n",
    "\n",
    "    # combined\n",
    "    pred = predictions_iq.append(predictions_sj)\n",
    "    true = Y_iq_test.append(Y_sj_test)\n",
    "    test_error.append(mean_absolute_error(pred, true))\n",
    "\n",
    "    train_pred = pred_train_iq.append(pred_train_sj)\n",
    "    train_true = Y_iq_train.append(Y_sj_train)\n",
    "    train_error.append(mean_absolute_error(train_pred, train_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['test'] = test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.index = range(2,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.233516</td>\n",
       "      <td>19.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.271062</td>\n",
       "      <td>18.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.258242</td>\n",
       "      <td>18.851648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.284799</td>\n",
       "      <td>17.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.184066</td>\n",
       "      <td>17.390110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.118132</td>\n",
       "      <td>17.376374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.122711</td>\n",
       "      <td>18.016484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.093407</td>\n",
       "      <td>18.277473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.088828</td>\n",
       "      <td>18.145604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.787546</td>\n",
       "      <td>18.708791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.783883</td>\n",
       "      <td>18.645604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.792125</td>\n",
       "      <td>18.618132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.840659</td>\n",
       "      <td>18.717033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.449634</td>\n",
       "      <td>19.291209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.121795</td>\n",
       "      <td>19.016484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.141026</td>\n",
       "      <td>19.195055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.744505</td>\n",
       "      <td>18.497253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.536630</td>\n",
       "      <td>18.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19.197802</td>\n",
       "      <td>17.936813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18.942308</td>\n",
       "      <td>17.365385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.973443</td>\n",
       "      <td>17.208791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.925824</td>\n",
       "      <td>17.123626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.491758</td>\n",
       "      <td>17.263736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18.454212</td>\n",
       "      <td>17.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18.347070</td>\n",
       "      <td>17.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.339744</td>\n",
       "      <td>17.244505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.305861</td>\n",
       "      <td>17.239011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.305861</td>\n",
       "      <td>17.239011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18.322344</td>\n",
       "      <td>17.412088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18.322344</td>\n",
       "      <td>17.412088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       test\n",
       "2   21.233516  19.035714\n",
       "3   21.271062  18.945055\n",
       "4   21.258242  18.851648\n",
       "5   21.284799  17.945055\n",
       "6   21.184066  17.390110\n",
       "7   21.118132  17.376374\n",
       "8   21.122711  18.016484\n",
       "9   21.093407  18.277473\n",
       "10  21.088828  18.145604\n",
       "11  20.787546  18.708791\n",
       "12  20.783883  18.645604\n",
       "13  20.792125  18.618132\n",
       "14  20.840659  18.717033\n",
       "15  20.449634  19.291209\n",
       "16  20.121795  19.016484\n",
       "17  20.141026  19.195055\n",
       "18  19.744505  18.497253\n",
       "19  19.536630  18.392857\n",
       "20  19.197802  17.936813\n",
       "21  18.942308  17.365385\n",
       "22  18.973443  17.208791\n",
       "23  18.925824  17.123626\n",
       "24  18.491758  17.263736\n",
       "25  18.454212  17.285714\n",
       "26  18.347070  17.250000\n",
       "27  18.339744  17.244505\n",
       "28  18.305861  17.239011\n",
       "29  18.305861  17.239011\n",
       "30  18.322344  17.412088\n",
       "31  18.322344  17.412088"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"dengue_features_train.csv\")\n",
    "y = pd.read_csv(\"dengue_labels_train.csv\")\n",
    "test = pd.read_csv(\"dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sj, X_iq, y_sj, y_iq = process(X, y, train = False)\n",
    "X_sj_test, X_iq_test = process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sj['y'] = y_sj\n",
    "X_iq['y'] = y_iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.glm(formula=formula,\n",
    "                data=X_sj,\n",
    "                family=sm.families.NegativeBinomial())\n",
    "model = model.fit()\n",
    "Y_pred_sj = model.predict(X_sj_test)\n",
    "\n",
    "model = smf.glm(formula=formula,\n",
    "                data=X_iq,\n",
    "                family=sm.families.NegativeBinomial(alpha=0.01))\n",
    "model = model.fit()\n",
    "Y_pred_iq = model.predict(X_iq_test)\n",
    "\n",
    "Y_pred = np.concatenate([Y_pred_sj, Y_pred_iq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"dengue_features_test.csv\")\n",
    "submission = test.loc[:,['city', 'year', 'weekofyear']].copy()\n",
    "submission['total_cases'] = Y_pred.astype(int)\n",
    "submission.to_csv('submission_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
